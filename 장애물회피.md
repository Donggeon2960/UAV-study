# UAV 5주차 PPT - 장애물 회피 알고리즘 완전판

안전한 비행을 위한 실시간 반응

---

# 슬라이드 50: 장애물 회피 개요

## 제목
**알고리즘 5: 장애물 회피 (Collision Avoidance)**

## 부제목
실시간으로 장애물을 감지하고 회피

---

## 왼쪽 영역: 역할 설명

```
┌──────────────────────────────────────┐
│ 입력 (센서 데이터)                    │
├──────────────────────────────────────┤
│ • LiDAR:     360° 점군 (20Hz)        │
│ • Depth 카메라: RGB-D (30Hz)          │
│ • 초음파:    전방 거리 (10Hz)         │
│ • 레이더:    장거리 (10Hz)            │
└──────────────────────────────────────┘
           ↓
    [장애물 감지 & 분류]
           ↓
┌──────────────────────────────────────┐
│ 장애물 정보                           │
├──────────────────────────────────────┤
│ 장애물 1: [2.5m, 30°, 정지]          │
│ 장애물 2: [5.0m, -15°, 이동 1m/s]    │
│ 장애물 3: [1.2m, 90°, 정지]          │
└──────────────────────────────────────┘
           ↓
    [회피 알고리즘]
           ↓
┌──────────────────────────────────────┐
│ 출력 (회피 명령)                      │
├──────────────────────────────────────┤
│ • 원래 속도:  [5.0, 0.0, 0.0] m/s    │
│ • 회피 속도:  [3.0, 2.0, 0.5] m/s    │
│ • 회피 방향:  우측 30°               │
│ • 긴급도:     중간 (2.5m 거리)       │
└──────────────────────────────────────┘
```

---

## 중단: 핵심 역할

### 📌 4가지 주요 기능

**1. 장애물 감지 (Detection)**
- 센서 데이터 수집 및 융합
- 장애물 위치, 크기, 속도 추정
- 정적 vs 동적 분류

**2. 위험도 평가 (Risk Assessment)**
- 충돌 시간(TTC) 계산
- 최소 안전 거리 확인
- 우선순위 결정

**3. 회피 동작 생성 (Avoidance Action)**
- 속도/방향 수정
- 긴급 정지 or 우회
- 원래 경로 복귀

**4. 실시간 재계획 (Re-planning)**
- 새 장애물 대응
- 동적 환경 적응
- 경로 계획과 통합

---

## 오른쪽 영역: 왜 필요한가?

### 안전의 최후 방어선

```
┌────────────────────────────────────┐
│ 경로 계획만으론 부족                │
├────────────────────────────────────┤
│ ✓ 사전 계획: 정적 장애물            │
│ ✗ 예측 불가: 새 장애물              │
│ ✗ 움직이는 장애물                  │
│ ✗ 센서 오차, 바람                  │
└────────────────────────────────────┘

┌────────────────────────────────────┐
│ 실시간 회피의 필요성                │
├────────────────────────────────────┤
│ • 사람/동물 갑자기 출현             │
│ • 다른 드론 근접                   │
│ • 새 (조류 충돌)                   │
│ • 건물/나무 (GPS 오차)             │
│ • 전선 (보이지 않음)               │
└────────────────────────────────────┘

통계:
• 드론 사고 30%: 장애물 충돌
• 실내 비행: 필수
• 자율 배송: 법적 요구사항
```

---

## 하단: 실행 특성

```
┌────────────────────────────────────┐
│ 센서 처리                           │
├────────────────────────────────────┤
│ 주파수: 10-30 Hz (센서마다 다름)    │
│ 지연: 50-100 ms                    │
│ CPU: ~5-10%                        │
└────────────────────────────────────┘

┌────────────────────────────────────┐
│ 회피 알고리즘                       │
├────────────────────────────────────┤
│ 주파수: 20-50 Hz                   │
│ 지연: 20-50 ms                     │
│ CPU: ~3-5%                         │
└────────────────────────────────────┘

┌────────────────────────────────────┐
│ 위치                               │
├────────────────────────────────────┤
│ PX4: src/modules/                  │
│      collision_prevention/         │
│                                    │
│ ArduPilot: libraries/              │
│            AP_Avoidance/           │
└────────────────────────────────────┘

총 지연 시간: ~100-200ms
(감지 → 판단 → 명령 → 실행)
```

---

## 발표 스크립트

"장애물 회피는 실시간으로 장애물을 감지하고 회피하는 알고리즘입니다. 안전한 비행의 최후 방어선입니다.

입력은 LiDAR, 깊이 카메라, 초음파, 레이더 등 다양한 센서 데이터입니다. 이들을 융합하여 장애물의 위치, 크기, 속도를 추정합니다. 예를 들어 2.5m 거리의 정지 장애물, 5m 거리의 1m/s로 이동하는 장애물을 감지합니다.

4가지 주요 기능이 있습니다. 장애물 감지는 센서 데이터를 융합하고 정적/동적을 분류합니다. 위험도 평가는 충돌 시간을 계산하고 우선순위를 결정합니다. 회피 동작 생성은 속도/방향을 수정하거나 긴급 정지합니다. 실시간 재계획은 새 장애물에 대응하고 경로 계획과 통합합니다.

경로 계획만으론 부족합니다. 사전 계획은 정적 장애물만 다루지만, 사람이 갑자기 나타나거나, 다른 드론이 근접하거나, 새가 날아오는 것은 예측할 수 없습니다. 통계에 따르면 드론 사고의 30%가 장애물 충돌이고, 실내 비행과 자율 배송에서는 법적으로 필수입니다.

실행 특성을 보면 센서 처리는 10-30Hz로 50-100ms 지연이 있고, 회피 알고리즘은 20-50Hz로 20-50ms 지연이 있습니다. 총 지연 시간은 감지부터 실행까지 100-200ms입니다."

---

## 이미지/다이어그램 추천

1. **센서 시야각**: LiDAR 360°, 카메라 90°
2. **회피 시나리오**: 전방 장애물 우회
3. **데이터 흐름**: 센서 → 알고리즘 → 명령

---
---

# 슬라이드 51: 센서 종류 및 특성

## 제목
**장애물 감지 센서**

## 부제목
각 센서의 장단점과 선택 기준

---

## 1. LiDAR (Light Detection and Ranging)

```
┌────────────────────────────────────┐
│ 원리: 레이저 펄스 반사 시간 측정    │
├────────────────────────────────────┤
│ 종류:                              │
│ • 2D LiDAR: 단일 평면 스캔          │
│ • 3D LiDAR: 다층 레이저             │
│ • Solid-state: 회전 부품 없음       │
└────────────────────────────────────┘

┌────────────────────────────────────┐
│ 사양                               │
├────────────────────────────────────┤
│ 거리: 0.5 ~ 100 m                  │
│ 정확도: ±2 cm                      │
│ 주파수: 10 ~ 20 Hz                 │
│ 시야각: 270° ~ 360°                │
│ 해상도: 0.25° ~ 1°                 │
│ 무게: 100 ~ 1000 g                 │
│ 가격: $100 ~ $10,000               │
└────────────────────────────────────┘

장점:
✓ 높은 정확도
✓ 넓은 거리 범위
✓ 날씨/조명 무관
✓ 3D 점군 생성

단점:
✗ 무겁고 비쌈
✗ 전력 소모 큰 편
✗ 유리/물 반사 오류
✗ 작은 물체 놓침 (와이어)

예시:
• Velodyne VLP-16: 16채널, $4,000
• Livox Mid-40: 저가형, $600
• RPLidar A1: 2D, $100
```

---

## 2. 깊이 카메라 (Depth Camera)

```
┌────────────────────────────────────┐
│ 원리:                              │
├────────────────────────────────────┤
│ • Stereo: 두 카메라 시차           │
│ • ToF: 적외선 비행 시간            │
│ • Structured Light: 패턴 투사       │
└────────────────────────────────────┘

┌────────────────────────────────────┐
│ 사양 (Intel RealSense D435i)        │
├────────────────────────────────────┤
│ 거리: 0.1 ~ 10 m                   │
│ 정확도: ±2% @ 2m                   │
│ 주파수: 30 ~ 90 Hz                 │
│ 시야각: 87° × 58°                  │
│ 해상도: 1280×720                   │
│ 무게: 72 g                         │
│ 가격: $200 ~ $400                  │
└────────────────────────────────────┘

장점:
✓ RGB + Depth 동시
✓ 고주파수 (90 Hz)
✓ 가볍고 저렴
✓ IMU 내장 (일부)

단점:
✗ 짧은 거리 (<10m)
✗ 햇빛 간섭
✗ 투명/검은색 물체
✗ 좁은 시야각

예시:
• Intel RealSense D435i: $300
• OAK-D: AI 내장, $300
• ZED 2i: Stereo, $450
```

---

## 3. 초음파 센서 (Ultrasonic)

```
┌────────────────────────────────────┐
│ 원리: 초음파 펄스 반향 시간         │
├────────────────────────────────────┤
│ 주파수: 40 kHz (사람 불가청)        │
│ 거리: 반향 시간 × 음속 / 2         │
└────────────────────────────────────┘

┌────────────────────────────────────┐
│ 사양 (HC-SR04)                      │
├────────────────────────────────────┤
│ 거리: 0.02 ~ 4 m                   │
│ 정확도: ±3 mm                      │
│ 주파수: 10 Hz                      │
│ 시야각: 15° (좁음)                 │
│ 무게: 10 g                         │
│ 가격: $1 ~ $5                      │
└────────────────────────────────────┘

장점:
✓ 매우 저렴
✓ 간단한 인터페이스
✓ 낮은 전력
✓ Pixhawk 기본 지원

단점:
✗ 짧은 거리 (<4m)
✗ 좁은 시야각
✗ 흡음 재질 감지 불가
✗ 느린 업데이트

사용 사례:
• 착륙 고도 측정
• 실내 벽 감지
• 저고도 호버링
• 백업 센서
```

---

## 4. 레이더 (Radar)

```
┌────────────────────────────────────┐
│ 원리: 전파 반사 (24/77 GHz)        │
├────────────────────────────────────┤
│ 도플러: 상대 속도 측정 가능         │
│ FMCW: 거리 + 속도 동시             │
└────────────────────────────────────┘

┌────────────────────────────────────┐
│ 사양 (mmWave Radar)                 │
├────────────────────────────────────┤
│ 거리: 0.5 ~ 100+ m                 │
│ 정확도: ±10 cm                     │
│ 주파수: 10 ~ 20 Hz                 │
│ 시야각: 120° ~ 150°                │
│ 무게: 50 ~ 200 g                   │
│ 가격: $50 ~ $500                   │
└────────────────────────────────────┘

장점:
✓ 장거리 (100m+)
✓ 속도 직접 측정
✓ 날씨 무관 (비/안개)
✓ 투명 물체 감지

단점:
✗ 낮은 해상도
✗ 작은 물체 놓침
✗ 금속 반사 강함
✗ 상대적 고가

예시:
• Ainstein US-D1: 드론용, $300
• TI AWR1843: 개발 킷, $200
```

---

## 하단: 센서 선택 가이드

| 용도 | 추천 센서 | 이유 |
|------|----------|------|
| **실내 비행** | 깊이 카메라 + 초음파 | 근거리, 고주파수, 가벼움 |
| **실외 고속** | LiDAR | 장거리, 높은 정확도 |
| **저가 구현** | 초음파 × 4 | 매우 저렴, 4방향 커버 |
| **전천후** | 레이더 | 비/안개/어둠 무관 |
| **AI 통합** | RGB-D 카메라 | 객체 인식 + 깊이 |

---

## 센서 융합

```
┌────────────────────────────────────┐
│ 최적 조합 예시                      │
├────────────────────────────────────┤
│ 전방: LiDAR (장거리)                │
│ 하방: 초음파 (착륙)                 │
│ 측면: 깊이 카메라 × 2 (넓은 시야)   │
│ 후방: 초음파 (저가)                 │
│                                    │
│ 총 비용: ~$1,000                   │
│ 360° 커버리지                      │
└────────────────────────────────────┘
```

---

## 발표 스크립트

"장애물 감지 센서 4종류를 상세히 봅시다.

LiDAR는 레이저 펄스 반사 시간으로 거리를 측정합니다. 2D는 단일 평면, 3D는 다층 레이저입니다. 0.5~100m 거리에 ±2cm 정확도이고 360도 시야각입니다. 날씨와 조명에 무관하고 3D 점군을 생성합니다. 하지만 무겁고(100~1000g) 비싸며($100~$10,000) 유리나 물 반사에 오류가 있고 전선 같은 작은 물체를 놓칩니다. Velodyne VLP-16은 16채널에 $4,000, RPLidar A1은 2D에 $100입니다.

깊이 카메라는 Stereo 시차, ToF 적외선, Structured Light 패턴 방식이 있습니다. Intel RealSense D435i는 0.1~10m에 ±2% 정확도, 30~90Hz, 87°×58° 시야각입니다. RGB와 Depth를 동시에 제공하고 가볍고(72g) 저렴합니다($300). 하지만 거리가 짧고 햇빛에 간섭이 있으며 투명하거나 검은색 물체는 감지하기 어렵습니다.

초음파는 40kHz 펄스 반향 시간으로 거리를 측정합니다. HC-SR04는 0.02~4m에 ±3mm 정확도이고 15도 시야각입니다. 매우 저렴하고($1~$5) 간단하며 Pixhawk가 기본 지원하지만, 거리가 짧고 시야각이 좁으며 흡음 재질을 감지하지 못합니다. 착륙 고도 측정이나 실내 벽 감지에 적합합니다.

레이더는 24/77GHz 전파 반사로 0.5~100m+ 거리를 측정하고 도플러로 속도를 직접 측정합니다. 날씨에 무관하고 투명 물체도 감지하지만 해상도가 낮고 작은 물체를 놓치며 상대적으로 비쌉니다.

센서 선택은 용도에 따라 다릅니다. 실내 비행은 깊이 카메라와 초음파, 실외 고속은 LiDAR, 저가 구현은 초음파 4개, 전천후는 레이더, AI 통합은 RGB-D 카메라를 추천합니다. 최적 조합은 전방 LiDAR, 하방 초음파, 측면 깊이 카메라 2개, 후방 초음파로 360도를 커버하며 총 $1,000입니다."

---
---

# 슬라이드 52: Potential Field (포텐셜 장) 상세

## 제목
**Potential Field 알고리즘**

## 부제목
가상의 힘으로 장애물 회피

---

## 상단: 핵심 아이디어

```
물리학에서 영감:
• 목표 = 자석 (인력)
• 장애물 = 같은 극 자석 (척력)
• 드론 = 철 입자 (힘의 합력 방향으로 이동)
```

---

## 중단: 수학적 정의

### 인력 (Attractive Force)

```
목표로 끌어당기는 힘

F_att = k_att × (x_goal - x_current)

k_att: 인력 게인 (보통 0.5 ~ 2.0)
x_goal: 목표 위치 [x, y, z]
x_current: 현재 위치 [x, y, z]

📖 예시:
목표 = [100, 50, -10] m
현재 = [80, 45, -10] m
k_att = 1.0

F_att = 1.0 × ([100, 50, -10] - [80, 45, -10])
      = [20, 5, 0] N

방향: 목표 쪽
크기: 거리에 비례
```

---

### 척력 (Repulsive Force)

```
장애물에서 밀어내는 힘

             ⎧  0                        d > d_safe
F_rep(obs) = ⎨  
             ⎩  k_rep × (1/d - 1/d_safe) × (x_current - x_obs) / d³
                                        d ≤ d_safe

k_rep: 척력 게인 (보통 50 ~ 500)
d: 장애물까지 거리
d_safe: 안전 거리 (보통 5 ~ 10 m)
x_obs: 장애물 위치

📖 예시:
장애물 = [82, 45, -10] m
현재 = [80, 45, -10] m
k_rep = 100
d_safe = 5 m

d = ||[80, 45, -10] - [82, 45, -10]||
  = 2 m

magnitude = 100 × (1/2 - 1/5) / 8
          = 100 × 0.3 / 8
          = 3.75

direction = ([80, 45, -10] - [82, 45, -10]) / 2
          = [-1, 0, 0]

F_rep = 3.75 × [-1, 0, 0]
      = [-3.75, 0, 0] N

방향: 장애물 반대쪽
크기: 거리 제곱에 반비례 (가까울수록 강함)
```

---

### 총 힘

```
F_total = F_att + Σ F_rep(obs_i)

여러 장애물:
F_total = F_att + F_rep(obs1) + F_rep(obs2) + ...

📖 예시:
F_att = [20, 5, 0]
F_rep(obs1) = [-3.75, 0, 0]
F_rep(obs2) = [0, -2, 0]

F_total = [20, 5, 0] + [-3.75, 0, 0] + [0, -2, 0]
        = [16.25, 3, 0] N

속도 명령:
v = F_total / mass  (또는 직접 사용)
v = [16.25, 3, 0] m/s

최대 속도 제한:
if ||v|| > v_max:
    v = v / ||v|| × v_max
```

---

## 하단: 완전한 코드

```python
import numpy as np

class PotentialField:
    def __init__(self, k_att=1.0, k_rep=100.0, 
                 d_safe=5.0, v_max=5.0):
        """
        Potential Field 회피 알고리즘
        
        Args:
            k_att: 인력 게인
            k_rep: 척력 게인
            d_safe: 안전 거리 (m)
            v_max: 최대 속도 (m/s)
        """
        self.k_att = k_att
        self.k_rep = k_rep
        self.d_safe = d_safe
        self.v_max = v_max
    
    
    def compute_velocity(self, current_pos, goal_pos, 
                         obstacles):
        """
        회피 속도 계산
        
        Args:
            current_pos: [x, y, z] 현재 위치
            goal_pos: [x, y, z] 목표 위치
            obstacles: [[x, y, z], ...] 장애물 리스트
        
        Returns:
            velocity: [vx, vy, vz] 속도 명령
        """
        
        # ═══════════════════════════════════════
        # Step 1: 인력 계산
        # ═══════════════════════════════════════
        to_goal = goal_pos - current_pos
        F_attractive = self.k_att * to_goal
        
        print(f"인력: {F_attractive}")
        
        
        # ═══════════════════════════════════════
        # Step 2: 척력 계산 (모든 장애물)
        # ═══════════════════════════════════════
        F_repulsive = np.zeros(3)
        
        for obs in obstacles:
            to_obs = current_pos - obs
            distance = np.linalg.norm(to_obs)
            
            # 안전 거리 내에 있는가?
            if distance < self.d_safe:
                # 0으로 나누기 방지
                if distance < 0.1:
                    distance = 0.1
                
                # 척력 크기 계산
                magnitude = self.k_rep * \
                    (1.0/distance - 1.0/self.d_safe) / \
                    (distance ** 2)
                
                # 방향: 장애물 반대쪽
                direction = to_obs / distance
                
                # 척력 벡터
                F_rep_single = magnitude * direction
                F_repulsive += F_rep_single
                
                print(f"장애물 {obs}: "
                      f"거리={distance:.2f}m, "
                      f"척력={F_rep_single}")
        
        
        # ═══════════════════════════════════════
        # Step 3: 총 힘
        # ═══════════════════════════════════════
        F_total = F_attractive + F_repulsive
        
        print(f"총 힘: {F_total}")
        
        
        # ═══════════════════════════════════════
        # Step 4: 속도 명령 (힘 = 속도로 사용)
        # ═══════════════════════════════════════
        velocity = F_total
        
        
        # ═══════════════════════════════════════
        # Step 5: 최대 속도 제한
        # ═══════════════════════════════════════
        speed = np.linalg.norm(velocity)
        
        if speed > self.v_max:
            velocity = velocity / speed * self.v_max
            print(f"속도 제한: {speed:.2f} → {self.v_max}")
        
        return velocity


# ═══════════════════════════════════════
# 사용 예시
# ═══════════════════════════════════════
pf = PotentialField(k_att=1.0, k_rep=100.0, 
                    d_safe=5.0, v_max=5.0)

# 현재 위치, 목표, 장애물
current = np.array([0.0, 0.0, -10.0])
goal = np.array([50.0, 0.0, -10.0])
obstacles = [
    np.array([10.0, 2.0, -10.0]),   # 전방 우측
    np.array([25.0, -1.0, -10.0]),  # 중간 좌측
]

# 시뮬레이션 (10초)
dt = 0.1  # 100ms
for t in np.arange(0, 10, dt):
    # 속도 계산
    velocity = pf.compute_velocity(current, goal, 
                                   obstacles)
    
    # 위치 업데이트
    current += velocity * dt
    
    # 목표 도달?
    distance_to_goal = np.linalg.norm(goal - current)
    if distance_to_goal < 1.0:
        print(f"목표 도달! t={t:.1f}s")
        break
    
    print(f"t={t:.1f}s, pos={current}, "
          f"vel={velocity}")
```

---

## 발표 스크립트

"Potential Field는 물리학에서 영감을 받았습니다. 목표는 자석처럼 인력을 발생시키고, 장애물은 같은 극 자석처럼 척력을 발생시킵니다. 드론은 철 입자처럼 힘의 합력 방향으로 이동합니다.

인력은 F_att = k_att × (목표 - 현재)입니다. k_att는 보통 0.5~2.0이고, 목표 쪽으로 거리에 비례하는 힘입니다. 예를 들어 목표 100m, 현재 80m, k_att=1.0이면 F_att=[20, 5, 0]N입니다.

척력은 복잡합니다. 거리가 안전 거리보다 크면 0이고, 작으면 (1/d - 1/d_safe) / d³에 비례합니다. 가까울수록 거리 제곱에 반비례하여 강해집니다. 예를 들어 장애물 2m 거리, k_rep=100, d_safe=5m이면 magnitude=3.75가 나옵니다. 방향은 장애물 반대쪽이므로 F_rep=[-3.75, 0, 0]N입니다.

총 힘은 인력과 모든 장애물의 척력을 더합니다. F_total = [20, 5, 0] + [-3.75, 0, 0] + [0, -2, 0] = [16.25, 3, 0]N입니다. 이것을 속도 명령으로 사용하고 최대 속도로 제한합니다.

완전한 코드를 봅시다. __init__에서 파라미터를 설정하고, compute_velocity에서 Step 1 인력 계산, Step 2 모든 장애물의 척력 계산, Step 3 총 힘, Step 4 속도 명령, Step 5 최대 속도 제한을 수행합니다. 사용 예시에서는 10초 시뮬레이션으로 0.1초마다 속도를 계산하고 위치를 업데이트하여 목표까지 이동합니다."

---
---

# 슬라이드 53: DWA (Dynamic Window Approach) 상세

## 제목
**DWA 알고리즘**

## 부제목
동적 윈도우로 안전한 속도 선택

---

## 상단: 핵심 아이디어

```
현재 속도 기준으로
물리적으로 도달 가능한 속도 범위 탐색
→ "동적 윈도우"

각 후보 속도를:
1. 시뮬레이션 (미래 예측)
2. 충돌 체크
3. 점수 계산
4. 최고 점수 선택
```

---

## 중단: 동적 윈도우 계산

```python
def compute_dynamic_window(current_vel, max_accel, 
                           dt, v_min_max):
    """
    동적 윈도우 계산
    
    Args:
        current_vel: [vx, vy, vz] 현재 속도
        max_accel: 최대 가속도 (m/s²)
        dt: 시간 간격 (s)
        v_min_max: [[vx_min, vx_max], 
                    [vy_min, vy_max], 
                    [vz_min, vz_max]]
    
    Returns:
        dw: [[vx_min, vx_max], ...]
    """
    
    # ═══════════════════════════════════════
    # 가속도 제한 윈도우
    # ═══════════════════════════════════════
    # 현재 속도 기준으로 가속 가능 범위
    v_accel_min = current_vel - max_accel * dt
    v_accel_max = current_vel + max_accel * dt
    
    # 📖 예시:
    # current_vel = [3.0, 1.0, 0.0] m/s
    # max_accel = 2.0 m/s²
    # dt = 0.1 s
    #
    # v_accel_min = [3.0, 1.0, 0.0] - 2.0 × 0.1
    #             = [2.8, 0.8, -0.2]
    # v_accel_max = [3.0, 1.0, 0.0] + 2.0 × 0.1
    #             = [3.2, 1.2, 0.2]
    
    
    # ═══════════════════════════════════════
    # 물리적 한계 윈도우
    # ═══════════════════════════════════════
    # 드론의 최대/최소 속도
    v_phys_min = np.array([v_min_max[0][0], 
                           v_min_max[1][0], 
                           v_min_max[2][0]])
    v_phys_max = np.array([v_min_max[0][1], 
                           v_min_max[1][1], 
                           v_min_max[2][1]])
    
    # 📖 예시:
    # v_min_max = [[-5, 5], [-5, 5], [-2, 2]]
    # v_phys_min = [-5, -5, -2]
    # v_phys_max = [5, 5, 2]
    
    
    # ═══════════════════════════════════════
    # 동적 윈도우 = 두 윈도우의 교집합
    # ═══════════════════════════════════════
    dw_min = np.maximum(v_accel_min, v_phys_min)
    dw_max = np.minimum(v_accel_max, v_phys_max)
    
    # 📖 예시:
    # dw_min = max([2.8, 0.8, -0.2], [-5, -5, -2])
    #        = [2.8, 0.8, -0.2]
    # dw_max = min([3.2, 1.2, 0.2], [5, 5, 2])
    #        = [3.2, 1.2, 0.2]
    
    dw = [[dw_min[0], dw_max[0]],
          [dw_min[1], dw_max[1]],
          [dw_min[2], dw_max[2]]]
    
    return dw
```

---

## 하단: 점수 함수

```python
def calculate_score(candidate_vel, current_pos, 
                    goal_pos, obstacles, 
                    predict_time=1.0):
    """
    후보 속도의 점수 계산
    
    Returns:
        score: 총점 (0 ~ 1)
        collision: 충돌 여부
    """
    
    # ═══════════════════════════════════════
    # Step 1: 미래 위치 예측
    # ═══════════════════════════════════════
    predicted_pos = current_pos + \
                    candidate_vel * predict_time
    
    
    # ═══════════════════════════════════════
    # Step 2: 충돌 체크
    # ═══════════════════════════════════════
    collision = False
    min_clearance = np.inf
    
    for obs in obstacles:
        distance = np.linalg.norm(predicted_pos - obs)
        min_clearance = min(min_clearance, distance)
        
        if distance < 2.0:  # 안전 거리
            collision = True
            break
    
    if collision:
        return 0.0, True  # 충돌하면 점수 0
    
    
    # ═══════════════════════════════════════
    # Step 3: 점수 계산 (3가지 기준)
    # ═══════════════════════════════════════
    
    # 3-1. 목표 방향 점수 (0 ~ 1)
    to_goal = goal_pos - predicted_pos
    to_goal_norm = to_goal / np.linalg.norm(to_goal)
    
    vel_norm = candidate_vel / \
               np.linalg.norm(candidate_vel)
    
    # 내적: -1 (반대) ~ +1 (같은 방향)
    heading_score = np.dot(vel_norm, to_goal_norm)
    heading_score = (heading_score + 1.0) / 2.0  # 0~1
    
    # 📖 예시:
    # to_goal = [10, 5, 0]
    # candidate_vel = [3, 2, 0]
    # 내적 = 0.98 → heading_score = 0.99
    
    
    # 3-2. 속도 점수 (0 ~ 1)
    # 빠를수록 좋음
    speed = np.linalg.norm(candidate_vel)
    max_speed = 5.0
    speed_score = min(speed / max_speed, 1.0)
    
    # 📖 예시:
    # speed = 3.6 m/s
    # speed_score = 3.6 / 5.0 = 0.72
    
    
    # 3-3. 장애물 거리 점수 (0 ~ 1)
    # 멀수록 좋음
    clearance_score = min(min_clearance / 10.0, 1.0)
    
    # 📖 예시:
    # min_clearance = 4.5 m
    # clearance_score = 4.5 / 10.0 = 0.45
    
    
    # ═══════════════════════════════════════
    # Step 4: 가중 평균
    # ═══════════════════════════════════════
    w_heading = 0.5
    w_speed = 0.3
    w_clearance = 0.2
    
    total_score = w_heading * heading_score + \
                  w_speed * speed_score + \
                  w_clearance * clearance_score
    
    # 📖 예시:
    # total_score = 0.5×0.99 + 0.3×0.72 + 0.2×0.45
    #             = 0.495 + 0.216 + 0.09
    #             = 0.801
    
    return total_score, False
```

---

## 완전한 DWA 코드

```python
class DynamicWindowApproach:
    def __init__(self, max_accel=2.0, v_max=5.0, 
                 dt=0.1, n_samples=10):
        self.max_accel = max_accel
        self.v_max = v_max
        self.dt = dt
        self.n_samples = n_samples
    
    
    def compute_velocity(self, current_pos, current_vel,
                         goal_pos, obstacles):
        """
        DWA 회피 속도 계산
        """
        
        # ═══════════════════════════════════════
        # Step 1: 동적 윈도우 계산
        # ═══════════════════════════════════════
        v_min_max = [[-self.v_max, self.v_max],
                     [-self.v_max, self.v_max],
                     [-2.0, 2.0]]  # 수직 제한
        
        dw = compute_dynamic_window(
            current_vel, self.max_accel, 
            self.dt, v_min_max
        )
        
        
        # ═══════════════════════════════════════
        # Step 2: 후보 속도 샘플링
        # ═══════════════════════════════════════
        best_vel = current_vel
        best_score = -np.inf
        
        n = self.n_samples
        
        for vx in np.linspace(dw[0][0], dw[0][1], n):
            for vy in np.linspace(dw[1][0], dw[1][1], n):
                for vz in np.linspace(dw[2][0], 
                                     dw[2][1], 
                                     max(n//2, 3)):
                    candidate = np.array([vx, vy, vz])
                    
                    # 점수 계산
                    score, collision = calculate_score(
                        candidate, current_pos, 
                        goal_pos, obstacles
                    )
                    
                    if score > best_score:
                        best_score = score
                        best_vel = candidate
        
        
        # ═══════════════════════════════════════
        # Step 3: 최고 점수 속도 반환
        # ═══════════════════════════════════════
        print(f"Best: vel={best_vel}, "
              f"score={best_score:.3f}")
        
        return best_vel


# ═══════════════════════════════════════
# 사용 예시
# ═══════════════════════════════════════
dwa = DynamicWindowApproach(max_accel=2.0, 
                            v_max=5.0, 
                            dt=0.1,
                            n_samples=10)

current_pos = np.array([0.0, 0.0, -10.0])
current_vel = np.array([3.0, 1.0, 0.0])
goal = np.array([50.0, 0.0, -10.0])
obstacles = [np.array([10.0, 2.0, -10.0])]

velocity = dwa.compute_velocity(current_pos, current_vel,
                                goal, obstacles)
```

---

## 발표 스크립트

"DWA는 동적 윈도우로 안전한 속도를 선택합니다. 현재 속도 기준으로 물리적으로 도달 가능한 속도 범위를 탐색하고, 각 후보를 시뮬레이션하여 점수를 계산합니다.

동적 윈도우 계산은 2단계입니다. 가속도 제한 윈도우는 현재 속도 ± 최대 가속도 × 시간입니다. 예를 들어 현재 3m/s, 최대 가속도 2m/s², 시간 0.1초면 2.8~3.2m/s입니다. 물리적 한계 윈도우는 드론의 최대/최소 속도입니다. 동적 윈도우는 두 윈도우의 교집합입니다.

점수 함수는 3가지 기준입니다. 목표 방향 점수는 속도와 목표 방향의 내적으로 -1~+1을 0~1로 변환합니다. 속도 점수는 빠를수록 좋습니다. 장애물 거리 점수는 멀수록 좋습니다. 가중 평균은 목표 방향 50%, 속도 30%, 장애물 거리 20%입니다.

완전한 DWA 코드는 Step 1 동적 윈도우 계산, Step 2 후보 속도 샘플링 (10×10×5=500개), Step 3 최고 점수 속도 반환입니다. 사용 예시에서는 현재 속도 3m/s로 장애물을 회피하여 목표까지 이동합니다."

---
---

# 슬라이드 54: VFH (Vector Field Histogram)

## 제목
**VFH 알고리즘**

## 부제목
히스토그램 기반 실시간 회피

---

## 상단: 핵심 아이디어

```
센서 데이터(점군)를:
1. 극좌표 히스토그램으로 변환
2. 장애물 밀도 계산
3. 가장 빈 방향 선택

장점:
✓ 실시간 처리 가능
✓ 노이즈에 강함
✓ LiDAR 데이터 적합
```

---

## 중단: 알고리즘 단계

### Step 1: 히스토그램 생성

```python
def create_histogram(lidar_points, current_pos, 
                     n_sectors=72):
    """
    극좌표 히스토그램 생성
    
    Args:
        lidar_points: [[x, y, z], ...] 점군
        current_pos: [x, y, z] 현재 위치
        n_sectors: 섹터 수 (360° / n_sectors)
    
    Returns:
        histogram: 각 섹터의 장애물 밀도
    """
    
    # 히스토그램 초기화
    histogram = np.zeros(n_sectors)
    sector_angle = 360.0 / n_sectors  # 5°
    
    # 각 점에 대해
    for point in lidar_points:
        # 상대 위치
        relative = point - current_pos
        
        # 거리
        distance = np.linalg.norm(relative[:2])  # XY만
        
        # 각도 (-180° ~ +180°)
        angle = np.arctan2(relative[1], relative[0])
        angle_deg = np.degrees(angle)
        
        # 섹터 인덱스
        sector_idx = int((angle_deg + 180) / 
                        sector_angle) % n_sectors
        
        # 거리 가중치 (가까울수록 높음)
        weight = max(0, 1.0 - distance / 10.0)
        
        # 히스토그램 누적
        histogram[sector_idx] += weight
    
    # 📖 예시:
    # n_sectors = 72 → 5° 간격
    # sector 0: 0° ~ 5°
    # sector 18: 90° ~ 95°
    # sector 36: 180° ~ 185°
    
    return histogram
```

---

### Step 2: 후보 방향 찾기

```python
def find_candidate_directions(histogram, threshold=0.5):
    """
    장애물이 적은 후보 방향들 찾기
    
    Args:
        histogram: 히스토그램
        threshold: 임계값 (이하만 통과 가능)
    
    Returns:
        candidates: [(start_idx, end_idx), ...]
    """
    
    n_sectors = len(histogram)
    candidates = []
    
    in_valley = False
    start_idx = -1
    
    # 히스토그램 스캔
    for i in range(n_sectors):
        if histogram[i] < threshold:
            if not in_valley:
                # Valley 시작
                in_valley = True
                start_idx = i
        else:
            if in_valley:
                # Valley 끝
                in_valley = False
                candidates.append((start_idx, i-1))
    
    # 마지막 Valley 처리
    if in_valley:
        candidates.append((start_idx, n_sectors-1))
    
    # 📖 예시:
    # histogram = [0.8, 0.9, 0.3, 0.2, 0.1, 0.3, 0.7, ...]
    #                        ↑________________↑
    #                      Valley (섹터 2~5)
    # candidates = [(2, 5)]
    
    return candidates
```

---

### Step 3: 최적 방향 선택

```python
def select_best_direction(candidates, goal_angle, 
                         n_sectors):
    """
    목표 방향에 가장 가까운 후보 선택
    
    Args:
        candidates: [(start, end), ...]
        goal_angle: 목표 각도 (deg)
        n_sectors: 섹터 수
    
    Returns:
        best_angle: 최적 각도 (deg)
    """
    
    if len(candidates) == 0:
        # 후보 없음 → 정지
        return None
    
    sector_angle = 360.0 / n_sectors
    
    best_candidate = None
    min_diff = np.inf
    
    for start, end in candidates:
        # Valley 중앙 각도
        center_idx = (start + end) / 2.0
        center_angle = (center_idx * sector_angle) - 180
        
        # 목표 각도와의 차이
        diff = abs(center_angle - goal_angle)
        
        # 180° 넘으면 반대 방향으로
        if diff > 180:
            diff = 360 - diff
        
        if diff < min_diff:
            min_diff = diff
            best_candidate = center_angle
    
    # 📖 예시:
    # candidates = [(10, 20), (50, 60)]
    # goal_angle = 85°
    # 
    # candidate 1: center = 75° → diff = 10°
    # candidate 2: center = 275° → diff = 170°
    # 
    # 선택: candidate 1 (75°)
    
    return best_candidate
```

---

## 하단: 완전한 VFH

```python
class VectorFieldHistogram:
    def __init__(self, n_sectors=72, threshold=0.5, 
                 v_max=5.0):
        self.n_sectors = n_sectors
        self.threshold = threshold
        self.v_max = v_max
    
    
    def compute_velocity(self, current_pos, goal_pos,
                         lidar_points):
        """
        VFH 회피 속도 계산
        """
        
        # ═══════════════════════════════════════
        # Step 1: 히스토그램 생성
        # ═══════════════════════════════════════
        histogram = create_histogram(
            lidar_points, current_pos, self.n_sectors
        )
        
        
        # ═══════════════════════════════════════
        # Step 2: 후보 방향 찾기
        # ═══════════════════════════════════════
        candidates = find_candidate_directions(
            histogram, self.threshold
        )
        
        
        # ═══════════════════════════════════════
        # Step 3: 목표 방향 계산
        # ═══════════════════════════════════════
        to_goal = goal_pos - current_pos
        goal_angle = np.degrees(
            np.arctan2(to_goal[1], to_goal[0])
        )
        
        
        # ═══════════════════════════════════════
        # Step 4: 최적 방향 선택
        # ═══════════════════════════════════════
        best_angle = select_best_direction(
            candidates, goal_angle, self.n_sectors
        )
        
        if best_angle is None:
            # 후보 없음 → 정지
            return np.zeros(3)
        
        
        # ═══════════════════════════════════════
        # Step 5: 속도 벡터 생성
        # ═══════════════════════════════════════
        angle_rad = np.radians(best_angle)
        
        velocity = np.array([
            self.v_max * np.cos(angle_rad),
            self.v_max * np.sin(angle_rad),
            0.0
        ])
        
        return velocity


# ═══════════════════════════════════════
# 사용 예시
# ═══════════════════════════════════════
vfh = VectorFieldHistogram(n_sectors=72, 
                           threshold=0.5, 
                           v_max=5.0)

# LiDAR 점군 (360개 점)
lidar_points = []
for i in range(360):
    angle = np.radians(i)
    distance = 5.0 + np.random.randn() * 0.5
    
    # 장애물: 30°~60°에 2m
    if 30 <= i <= 60:
        distance = 2.0
    
    x = distance * np.cos(angle)
    y = distance * np.sin(angle)
    lidar_points.append([x, y, 0])

lidar_points = np.array(lidar_points)

current = np.array([0.0, 0.0, 0.0])
goal = np.array([10.0, 0.0, 0.0])

velocity = vfh.compute_velocity(current, goal, 
                                lidar_points)
```

---

## 발표 스크립트

"VFH는 히스토그램 기반 실시간 회피입니다. 센서 데이터를 극좌표 히스토그램으로 변환하고, 장애물 밀도를 계산하여 가장 빈 방향을 선택합니다. 실시간 처리가 가능하고 노이즈에 강하며 LiDAR 데이터에 적합합니다.

Step 1 히스토그램 생성은 72개 섹터로 5도 간격입니다. 각 LiDAR 점에 대해 각도를 계산하고 섹터 인덱스를 구합니다. 거리 가중치는 가까울수록 높습니다.

Step 2 후보 방향 찾기는 히스토그램을 스캔하여 임계값 이하인 Valley를 찾습니다. 예를 들어 섹터 2~5가 0.1~0.3으로 낮으면 후보입니다.

Step 3 최적 방향 선택은 각 후보의 중앙 각도를 계산하고 목표 각도와의 차이를 비교합니다. 가장 가까운 것을 선택합니다.

완전한 VFH는 Step 1 히스토그램 생성, Step 2 후보 방향 찾기, Step 3 목표 방향 계산, Step 4 최적 방향 선택, Step 5 속도 벡터 생성입니다. 사용 예시에서는 360개 LiDAR 점 중 30~60도에 2m 장애물이 있고, 이를 회피하여 목표로 이동합니다."

---
---

# 슬라이드 55: 센서 데이터 처리

## 제목
**센서 데이터 처리 파이프라인**

## 부제목
원시 데이터에서 장애물 정보까지

---

## 상단: 전체 파이프라인

```
센서 원시 데이터
    ↓
[1. 노이즈 제거]
    ↓
필터링된 데이터
    ↓
[2. 좌표 변환]
    ↓
드론 중심 좌표
    ↓
[3. 장애물 추출]
    ↓
장애물 위치 리스트
    ↓
[4. 클러스터링]
    ↓
장애물 객체
    ↓
[5. 추적]
    ↓
장애물 속도/예측
```

---

## 중단: 각 단계 상세

### 1. 노이즈 제거

```python
def filter_noise(points, distance_threshold=0.1):
    """
    통계적 이상값 제거 (Statistical Outlier Removal)
    
    각 점의 이웃 거리 평균이
    전체 평균 + k×표준편차보다 크면 제거
    """
    
    from sklearn.neighbors import NearestNeighbors
    
    # k=10 최근접 이웃
    nbrs = NearestNeighbors(n_neighbors=10).fit(points)
    distances, indices = nbrs.kneighbors(points)
    
    # 각 점의 평균 거리
    mean_distances = distances.mean(axis=1)
    
    # 전체 평균 및 표준편차
    global_mean = mean_distances.mean()
    global_std = mean_distances.std()
    
    # 이상값 제거 (평균 + 2σ 초과)
    threshold = global_mean + 2 * global_std
    mask = mean_distances < threshold
    
    filtered_points = points[mask]
    
    # 📖 예시:
    # 1000개 점 중 50개가 이상값
    # → 950개 점 반환
    
    return filtered_points
```

---

### 2. 좌표 변환

```python
def transform_to_drone_frame(points_world, 
                             drone_pos, 
                             drone_quat):
    """
    월드 좌표 → 드론 중심 좌표
    
    회전 + 평행이동
    """
    
    from scipy.spatial.transform import Rotation
    
    # 쿼터니언 → 회전 행렬
    R = Rotation.from_quat(drone_quat).as_matrix()
    
    # 월드 → 드론
    points_drone = []
    for p_world in points_world:
        # 평행이동
        p_relative = p_world - drone_pos
        
        # 회전 (역회전)
        p_drone = R.T @ p_relative
        
        points_drone.append(p_drone)
    
    # 📖 예시:
    # 드론 위치 = [10, 5, -10] m
    # 드론 자세 = Roll 10°
    # 
    # 점 [12, 5, -10] (월드)
    # → [2, 0, 0] (드론 전방 2m)
    
    return np.array(points_drone)
```

---

### 3. 장애물 추출

```python
def extract_obstacles(points_drone, 
                     min_distance=0.5, 
                     max_distance=20.0):
    """
    유효 거리 범위의 점만 추출
    
    너무 가까운 점 = 지면/드론 자체
    너무 먼 점 = 관심 없음
    """
    
    obstacles = []
    
    for point in points_drone:
        distance = np.linalg.norm(point)
        
        # 유효 범위 체크
        if min_distance < distance < max_distance:
            obstacles.append(point)
    
    # 📖 예시:
    # 5000개 점 중:
    # - 100개는 0.3m (지면)
    # - 4500개는 0.5~20m (유효)
    # - 400개는 25m+ (멀리)
    # 
    # → 4500개 장애물 점 반환
    
    return np.array(obstacles)
```

---

### 4. 클러스터링

```python
def cluster_obstacles(obstacles, eps=0.5, 
                     min_samples=5):
    """
    DBSCAN 클러스터링
    
    가까운 점들을 하나의 장애물 객체로 묶음
    """
    
    from sklearn.cluster import DBSCAN
    
    if len(obstacles) == 0:
        return []
    
    # DBSCAN 클러스터링
    clustering = DBSCAN(eps=eps, 
                       min_samples=min_samples).fit(obstacles)
    
    labels = clustering.labels_
    
    # 각 클러스터의 중심점
    obstacle_objects = []
    
    for label in set(labels):
        if label == -1:
            continue  # 노이즈
        
        # 클러스터에 속한 점들
        cluster_points = obstacles[labels == label]
        
        # 중심점 (평균)
        center = cluster_points.mean(axis=0)
        
        # 크기 (최대 범위)
        size = (cluster_points.max(axis=0) - 
                cluster_points.min(axis=0))
        
        obstacle_objects.append({
            'center': center,
            'size': size,
            'points': cluster_points
        })
    
    # 📖 예시:
    # 4500개 점 → 15개 장애물 객체
    # 
    # 객체 1: 중심 [5, 2, 0], 크기 [1, 1, 2]
    # 객체 2: 중심 [8, -3, 0], 크기 [0.5, 0.5, 1.5]
    # ...
    
    return obstacle_objects
```

---

### 5. 추적 (Tracking)

```python
class ObstacleTracker:
    def __init__(self, max_age=5):
        self.tracks = []
        self.next_id = 0
        self.max_age = max_age
    
    
    def update(self, detections, dt):
        """
        칼만 필터로 장애물 추적
        
        위치 + 속도 추정
        """
        
        # ═══════════════════════════════════════
        # Step 1: 매칭 (헝가리안 알고리즘)
        # ═══════════════════════════════════════
        from scipy.optimize import linear_sum_assignment
        
        if len(self.tracks) == 0:
            # 새 트랙 생성
            for det in detections:
                self.tracks.append({
                    'id': self.next_id,
                    'pos': det['center'],
                    'vel': np.zeros(3),
                    'age': 0
                })
                self.next_id += 1
            return self.tracks
        
        # 비용 행렬 (거리)
        cost_matrix = np.zeros((len(self.tracks), 
                               len(detections)))
        
        for i, track in enumerate(self.tracks):
            for j, det in enumerate(detections):
                cost_matrix[i, j] = np.linalg.norm(
                    track['pos'] - det['center']
                )
        
        # 최적 매칭
        row_ind, col_ind = linear_sum_assignment(
            cost_matrix
        )
        
        
        # ═══════════════════════════════════════
        # Step 2: 트랙 업데이트
        # ═══════════════════════════════════════
        matched_tracks = set()
        matched_detections = set()
        
        for i, j in zip(row_ind, col_ind):
            if cost_matrix[i, j] < 2.0:  # 2m 이내
                # 매칭 성공
                track = self.tracks[i]
                det = detections[j]
                
                # 속도 추정
                vel = (det['center'] - track['pos']) / dt
                
                # 지수 평활 (Exponential Smoothing)
                alpha = 0.3
                track['vel'] = (alpha * vel + 
                               (1-alpha) * track['vel'])
                
                track['pos'] = det['center']
                track['age'] = 0
                
                matched_tracks.add(i)
                matched_detections.add(j)
        
        
        # ═══════════════════════════════════════
        # Step 3: 새 트랙 & 오래된 트랙 제거
        # ═══════════════════════════════════════
        # 매칭 안 된 트랙: age 증가
        for i, track in enumerate(self.tracks):
            if i not in matched_tracks:
                track['age'] += 1
        
        # 오래된 트랙 제거
        self.tracks = [t for t in self.tracks 
                      if t['age'] < self.max_age]
        
        # 새 트랙 추가
        for j, det in enumerate(detections):
            if j not in matched_detections:
                self.tracks.append({
                    'id': self.next_id,
                    'pos': det['center'],
                    'vel': np.zeros(3),
                    'age': 0
                })
                self.next_id += 1
        
        return self.tracks
```

---

## 발표 스크립트

"센서 데이터 처리는 5단계 파이프라인입니다. 원시 데이터에서 노이즈 제거, 좌표 변환, 장애물 추출, 클러스터링, 추적을 거쳐 장애물 속도와 예측까지 제공합니다.

1단계 노이즈 제거는 통계적 이상값 제거입니다. k=10 최근접 이웃의 평균 거리가 전체 평균+2σ보다 크면 제거합니다. 1000개 중 50개 이상값을 제거하여 950개를 반환합니다.

2단계 좌표 변환은 월드 좌표를 드론 중심 좌표로 변환합니다. 쿼터니언을 회전 행렬로 변환하고 평행이동과 역회전을 적용합니다.

3단계 장애물 추출은 유효 거리 범위만 추출합니다. 0.5m 미만은 지면, 20m 초과는 관심 없음으로 제거합니다.

4단계 클러스터링은 DBSCAN으로 가까운 점들을 하나의 객체로 묶습니다. 4500개 점을 15개 장애물 객체로 변환하고 각각의 중심, 크기, 점들을 저장합니다.

5단계 추적은 칼만 필터로 장애물을 추적합니다. 헝가리안 알고리즘으로 이전 트랙과 현재 감지를 매칭하고, 속도를 추정하며, 새 트랙 추가와 오래된 트랙 제거를 수행합니다."

---
---

# 슬라이드 56: PX4/ArduPilot 통합

## 제목
**실제 드론에 통합하기**

## 부제목
PX4/ArduPilot Collision Prevention

---

## 상단: PX4 통합

### 파라미터 설정

```
┌────────────────────────────────────┐
│ PX4 파라미터                        │
├────────────────────────────────────┤
│ CP_DIST = 5.0                      │
│  • 안전 거리 (m)                   │
│  • 이 거리 내 장애물 감지 시 회피   │
│                                    │
│ CP_DELAY = 0.4                     │
│  • 제동 시간 (초)                  │
│  • 정지까지 소요 시간 고려          │
│                                    │
│ CP_GUIDE_ANG = 30.0                │
│  • 회피 각도 (도)                  │
│  • 최대 회피 각도 제한              │
│                                    │
│ MPC_COL_PREV_D = 1                 │
│  • 충돌 방지 활성화                │
│  • 0=비활성, 1=활성                │
│                                    │
│ MPC_COL_PREV_DLY = 0.0             │
│  • 센서 지연 보상 (초)              │
│  • LiDAR/카메라 지연 시간           │
│                                    │
│ MPC_COL_PREV_ANG = 45.0            │
│  • 센서 시야각 (도)                │
│  • ±45° = 90° 전방                 │
└────────────────────────────────────┘
```

---

### 센서 연결

```cpp
// PX4 Collision Prevention 모듈
// src/modules/collision_prevention/

// ═══════════════════════════════════════
// Step 1: 센서 데이터 구독
// ═══════════════════════════════════════
uORB::Subscription _obstacle_distance_sub{
    ORB_ID(obstacle_distance)
};

// OBSTACLE_DISTANCE 메시지 수신
obstacle_distance_s obstacle_distance;
if (_obstacle_distance_sub.update(&obstacle_distance)) {
    // 센서 데이터 받음
    
    // 📖 메시지 구조:
    // - distances[72]: 각 섹터별 거리 (cm)
    // - increment: 섹터 간 각도 (5°)
    // - min_distance/max_distance: 센서 범위
    // - angle_offset: 시작 각도 오프셋
    
    for (int i = 0; i < 72; i++) {
        uint16_t distance_cm = 
            obstacle_distance.distances[i];
        
        float distance_m = distance_cm / 100.0f;
        float angle_deg = i * 5.0f;  // 5° 간격
        
        // 안전 거리 체크
        if (distance_m < _param_cp_dist.get()) {
            // 장애물 가까움!
            _obstacles[i] = distance_m;
        }
    }
}


// ═══════════════════════════════════════
// Step 2: 속도 제한 계산
// ═══════════════════════════════════════
void modifySetpoint(matrix::Vector2f &setpoint_xy) {
    // 원래 속도 명령
    float vel_x = setpoint_xy(0);  // 전방
    float vel_y = setpoint_xy(1);  // 우측
    
    // 속도 방향 각도
    float vel_angle = atan2f(vel_y, vel_x);
    float vel_angle_deg = 
        math::degrees(vel_angle);
    
    // 해당 방향의 장애물 거리
    int sector = (int)((vel_angle_deg + 180.0f) / 
                      5.0f) % 72;
    float obstacle_dist = _obstacles[sector];
    
    // 속도 제한 계산
    float scale = 1.0f;
    
    if (obstacle_dist < _param_cp_dist.get()) {
        // 거리에 비례하여 감속
        scale = obstacle_dist / 
               _param_cp_dist.get();
        
        // 최소 10% 속도 유지
        scale = math::max(scale, 0.1f);
    }
    
    // 속도 제한 적용
    setpoint_xy *= scale;
    
    // 📖 예시:
    // 원래 속도 = [5.0, 0.0] m/s (전방)
    // 장애물 거리 = 2.5m (안전 거리 5m)
    // scale = 2.5 / 5.0 = 0.5
    // 제한 속도 = [2.5, 0.0] m/s
}


// ═══════════════════════════════════════
// Step 3: 회피 방향 제안
// ═══════════════════════════════════════
void computeGuidance(matrix::Vector2f &guidance) {
    // 좌우 장애물 비교
    float left_dist = 0.0f;
    float right_dist = 0.0f;
    
    // 좌측 (-90° ~ -30°)
    for (int i = 18; i < 30; i++) {
        left_dist += _obstacles[i];
    }
    left_dist /= 12.0f;
    
    // 우측 (30° ~ 90°)
    for (int i = 42; i < 54; i++) {
        right_dist += _obstacles[i];
    }
    right_dist /= 12.0f;
    
    // 더 빈 쪽으로 유도
    if (left_dist > right_dist) {
        // 좌측이 더 빔
        guidance(0) = 0.5f;  // 전방 유지
        guidance(1) = -1.0f;  // 좌측으로
    } else {
        // 우측이 더 빔
        guidance(0) = 0.5f;
        guidance(1) = 1.0f;  // 우측으로
    }
}
```

---

## 하단: ArduPilot 통합

```cpp
// ArduPilot Avoidance 라이브러리
// libraries/AP_Avoidance/

// ═══════════════════════════════════════
// 센서 인터페이스
// ═══════════════════════════════════════
class AP_Avoidance {
public:
    // 장애물 데이터 업데이트
    void handle_msg(const mavlink_message_t &msg);
    
    // 회피 속도 계산
    bool get_vector_avoidance(
        Vector2f &desired_vel_cms,  // 원하는 속도
        Vector2f &modified_vel_cms  // 수정된 속도
    );
    
private:
    // 장애물 데이터베이스
    AP_OADatabase _oadatabase;
    
    // 회피 알고리즘
    AP_OA_BendyRuler _oabendy;
    AP_OA_Dijkstra _oadijkstra;
};


// ═══════════════════════════════════════
// BendyRuler 알고리즘
// ═══════════════════════════════════════
bool AP_OA_BendyRuler::search_path_xy(
    const Vector2f &current_pos,
    const Vector2f &destination,
    Vector2f &result_origin,
    Vector2f &result_destination
) {
    // 목표 방향
    Vector2f dest_dir = destination - current_pos;
    
    // 좌우로 "구부리기"
    const float bend_angle = 45.0f;
    
    Vector2f bend_left = 
        dest_dir.rotate(-radians(bend_angle));
    Vector2f bend_right = 
        dest_dir.rotate(radians(bend_angle));
    
    // 충돌 체크
    bool path_clear = check_path_clear(
        current_pos, destination
    );
    
    bool left_clear = check_path_clear(
        current_pos, 
        current_pos + bend_left
    );
    
    bool right_clear = check_path_clear(
        current_pos, 
        current_pos + bend_right
    );
    
    // 최적 경로 선택
    if (path_clear) {
        // 직진 가능
        result_destination = destination;
        return true;
    } else if (left_clear) {
        // 좌측 우회
        result_destination = 
            current_pos + bend_left;
        return true;
    } else if (right_clear) {
        // 우측 우회
        result_destination = 
            current_pos + bend_right;
        return true;
    }
    
    // 모든 경로 막힘
    return false;
}
```

---

## 발표 스크립트

"PX4와 ArduPilot 통합을 봅시다.

PX4 파라미터는 CP_DIST=5.0m 안전 거리, CP_DELAY=0.4초 제동 시간, CP_GUIDE_ANG=30도 회피 각도, MPC_COL_PREV_D=1 충돌 방지 활성화를 설정합니다.

센서 연결은 3단계입니다. Step 1에서 OBSTACLE_DISTANCE 메시지를 구독하여 72개 섹터별 거리를 받습니다. Step 2에서 속도 제한을 계산합니다. 원래 속도 방향의 장애물 거리를 확인하고, 안전 거리 내면 비례하여 감속합니다. 예를 들어 5m/s 속도에 2.5m 장애물이면 0.5배로 감속하여 2.5m/s가 됩니다. Step 3에서 회피 방향을 제안합니다. 좌우 장애물을 비교하여 더 빈 쪽으로 유도합니다.

ArduPilot은 AP_Avoidance 라이브러리를 사용합니다. handle_msg로 장애물 데이터를 업데이트하고, get_vector_avoidance로 회피 속도를 계산합니다. BendyRuler 알고리즘은 목표 방향에서 좌우 45도로 구부려보고, 직진-좌측-우측 순으로 충돌 체크하여 최적 경로를 선택합니다."

---
---

# 슬라이드 57: 실전 예시 - 실내 복도 비행

## 제목
**실전 시나리오: 실내 복도 비행**

## 부제목
좁은 공간에서 장애물 회피

---

## 시나리오: 폭 3m 복도

```
드론이 폭 3m 복도를 통과
중간에 사람이 갑자기 나타남
```

---

## 타임라인

### t = 0.0s: 정상 비행

```
┌────────────────────────────────────┐
│ 상황                                │
├────────────────────────────────────┤
│ 위치: [0, 0, -1.5] m (복도 중앙)    │
│ 속도: [2.0, 0.0, 0.0] m/s (전방)    │
│ 목표: [50, 0, -1.5] m               │
└────────────────────────────────────┘

센서:
• 좌측 벽: 1.5 m
• 우측 벽: 1.5 m
• 전방: >20 m (자유)

회피 알고리즘:
• 동작 없음 (장애물 없음)
• 속도 유지: [2.0, 0.0, 0.0] m/s

그래프:
위치 ─────────────
     (중앙 유지)
```

---

### t = 2.0s: 장애물 감지

```
┌────────────────────────────────────┐
│ 사람 출현!                          │
├────────────────────────────────────┤
│ 사람 위치: [8.0, 0.0, -1.5] m       │
│ 드론 위치: [4.0, 0.0, -1.5] m       │
│ 상대 거리: 4.0 m                   │
└────────────────────────────────────┘

센서:
• LiDAR: 전방 4.0m 장애물 감지
• 크기: 0.5m 폭 × 2.0m 높이

회피 알고리즘 동작:
• Potential Field 계산
  - 인력 (목표): [46, 0, 0]
  - 척력 (사람): [-18.75, 0, 0]
  - 총 힘: [27.25, 0, 0]
  
• 아직 안전 거리 (5m) 밖
• 속도 유지

⚠️ 경고: "Obstacle detected ahead, 4.0m"
```

---

### t = 3.0s: 회피 시작

```
┌────────────────────────────────────┐
│ 회피 동작 시작                      │
├────────────────────────────────────┤
│ 사람 위치: [8.0, 0.0, -1.5] m       │
│ 드론 위치: [6.0, 0.0, -1.5] m       │
│ 상대 거리: 2.0 m                   │
└────────────────────────────────────┘

센서:
• 전방: 2.0m (긴급!)
• 좌측 벽: 1.5m
• 우측 벽: 1.5m

회피 알고리즘:
• DWA 실행
  - 동적 윈도우: [-0.5~2.5] m/s (전방)
  - 후보 샘플링: 10×10 = 100개
  
• 점수 계산:
  - 직진 [2.0, 0.0]: 충돌 → 0점
  - 좌측 [1.5, -0.8]: 75점 (최고)
  - 우측 [1.5, 0.8]: 70점
  
• 선택: 좌측 우회 [1.5, -0.8]

속도 변경:
[2.0, 0.0, 0.0] → [1.5, -0.8, 0.0] m/s

드론 동작:
• 감속 (2.0 → 1.5 m/s)
• 좌측으로 이동 시작

🔔 알림: "Avoiding left, speed reduced"
```

---

### t = 4.0s: 우회 중

```
┌────────────────────────────────────┐
│ 사람 옆 통과 중                     │
├────────────────────────────────────┤
│ 사람 위치: [8.0, 0.0, -1.5] m       │
│ 드론 위치: [7.5, -0.8, -1.5] m      │
│ 상대 거리: 1.2 m (옆)               │
└────────────────────────────────────┘

센서:
• 전방-좌측: 1.2m (사람)
• 좌측 벽: 0.7m (가까움!)
• 우측 벽: 2.3m

회피 알고리즘:
• 좌측 벽 근접 감지
• 우측으로 약간 보정

속도 수정:
[1.5, -0.8, 0.0] → [1.5, -0.3, 0.0] m/s

드론 동작:
• 좌측 이동 감소
• 벽 충돌 방지
```

---

### t = 5.0s: 복귀 시작

```
┌────────────────────────────────────┐
│ 장애물 통과 완료                    │
├────────────────────────────────────┤
│ 사람 위치: [8.0, 0.0, -1.5] m       │
│ 드론 위치: [9.0, -0.5, -1.5] m      │
│ 상대 거리: 1.1 m (뒤)               │
└────────────────────────────────────┘

센서:
• 전방: >20m (자유)
• 좌측 벽: 1.0m
• 우측 벽: 2.0m

회피 알고리즘:
• 장애물 없음
• 중앙으로 복귀

속도 변경:
[1.5, -0.3, 0.0] → [2.0, 0.3, 0.0] m/s

드론 동작:
• 가속 (1.5 → 2.0 m/s)
• 우측으로 중앙 복귀
```

---

### t = 7.0s: 정상 비행 복귀

```
┌────────────────────────────────────┐
│ 정상 상태 복귀                      │
├────────────────────────────────────┤
│ 위치: [13.0, 0.0, -1.5] m           │
│ 속도: [2.0, 0.0, 0.0] m/s           │
└────────────────────────────────────┘

센서:
• 좌측 벽: 1.5m
• 우측 벽: 1.5m
• 전방: >20m

회피 알고리즘:
• 동작 없음

✓ 성공: "Obstacle avoided, resuming normal flight"
```

---

## 그래프

```
Y 위치 (m)
 1.5 ┤  벽
 1.0 ┤
 0.5 ┤
 0.0 ┼────╱╲────────────
-0.5 ┤    ╲╱  (우회)
-1.0 ┤
-1.5 ┤  벽
     0  2  4  6  8  10  12  [X, m]
              ● (사람)

속도 (m/s)
 2.5 ┤
 2.0 ┼────╲    ╱────────
 1.5 ┤     ╲──╱  (감속)
 1.0 ┤
 0.5 ┤
 0.0 ┤
     0  1  2  3  4  5  6  7  [t, s]
```

---

## 교훈

```
✅ 성공 요인:
• 조기 감지 (4m)
• 점진적 감속
• 양쪽 벽 인식
• 중앙 복귀

⚠️ 위험 요소:
• 0.7m까지 벽 근접
• 1.2m까지 사람 근접
• 좁은 공간 (3m)

🔧 개선 방안:
• 더 일찍 감속 (6m)
• 더 큰 안전 여유 (1.0m)
• 사람 움직임 예측
```

---

## 발표 스크립트

"실전 시나리오로 폭 3m 복도 비행을 봅시다. 중간에 사람이 갑자기 나타나는 상황입니다.

t=0초는 정상 비행으로 복도 중앙 0m, 속도 2m/s로 전방 50m 목표로 이동합니다. 좌우 벽은 1.5m이고 전방은 자유입니다.

t=2초에 장애물을 감지합니다. 전방 8m에 사람이 나타났고 현재 4m입니다. LiDAR가 감지하고 Potential Field를 계산합니다. 인력 46, 척력 -18.75, 총 힘 27.25입니다. 아직 안전 거리 5m 밖이라 속도를 유지하지만 경고를 표시합니다.

t=3초에 회피를 시작합니다. 거리 2m로 긴급 상황입니다. DWA를 실행하여 100개 후보를 샘플링합니다. 직진은 충돌로 0점, 좌측 우회는 75점, 우측은 70점이 나와 좌측을 선택합니다. 속도를 2m/s에서 1.5m/s로 감속하고 좌측 -0.8m/s로 이동합니다.

t=4초에 우회 중입니다. 사람 옆 1.2m를 통과하는데 좌측 벽이 0.7m로 가까워집니다. 우측으로 약간 보정하여 -0.8에서 -0.3m/s로 수정합니다.

t=5초에 복귀를 시작합니다. 장애물을 통과했고 전방이 자유입니다. 가속하여 2m/s로 복귀하고 중앙으로 우측 0.3m/s 이동합니다.

t=7초에 정상 비행으로 완전히 복귀했습니다.

그래프를 보면 Y 위치가 좌측으로 우회했다가 중앙으로 복귀하고, 속도는 2m/s에서 1.5m/s로 감속했다가 다시 2m/s로 가속합니다.

성공 요인은 조기 감지 4m, 점진적 감속, 양쪽 벽 인식, 중앙 복귀입니다. 위험 요소는 0.7m까지 벽 근접, 1.2m까지 사람 근접, 좁은 3m 공간입니다. 개선 방안은 더 일찍 6m에서 감속, 더 큰 1.0m 안전 여유, 사람 움직임 예측입니다."

---
---

# 슬라이드 58: 요약 및 실습 과제

## 제목
**장애물 회피 요약 및 실습**

## 부제목
이론에서 실전으로

---

## 핵심 요약

### 3가지 핵심 알고리즘

```
Potential Field         DWA              VFH
(포텐셜 장)          (동적 윈도우)    (히스토그램)
     ↓                    ↓                ↓
  간단/직관          최적/안전        실시간/효율
  인력+척력          후보 샘플링      섹터 밀도
     ↓                    ↓                ↓
실내/단순 환경    복잡한 환경      LiDAR 데이터
```

### 핵심 원리

```
✓ 조기 감지: 4-6m 거리
✓ 점진적 반응: 급격한 회피 금지
✓ 안전 여유: 최소 1m
✓ 센서 융합: 다중 센서
✓ 중앙 복귀: 정상 경로 복귀
```

---

## 실습 과제 1: Potential Field 구현

```
┌────────────────────────────────────┐
│ 목표: 포텐셜 장 시뮬레이터          │
├────────────────────────────────────┤
│ 1. Python으로 2D 구현              │
│    • 인력/척력 계산                │
│    • 총 힘 → 속도 변환             │
│                                    │
│ 2. 시각화                          │
│    • matplotlib 애니메이션          │
│    • 힘 벡터 표시                  │
│    • 경로 추적                     │
│                                    │
│ 3. 파라미터 튜닝                   │
│    • k_att 조정 (0.5 ~ 2.0)        │
│    • k_rep 조정 (50 ~ 500)         │
│    • d_safe 조정 (3 ~ 10m)         │
│                                    │
│ 4. Local Minima 해결               │
│    • 랜덤 워크 추가                │
│    • 방향 변경 전략                │
└────────────────────────────────────┘

예상 시간: 3~4시간
난이도: ★★★☆☆
```

---

## 실습 과제 2: DWA 구현

```
┌────────────────────────────────────┐
│ 목표: 동적 윈도우 시뮬레이터        │
├────────────────────────────────────┤
│ 1. Python으로 2D 구현              │
│    • 동적 윈도우 계산              │
│    • 후보 샘플링 (10×10)           │
│    • 점수 함수 (3가지 기준)         │
│                                    │
│ 2. 복잡한 환경 테스트              │
│    • 정적 장애물 5개               │
│    • 동적 장애물 2개 (이동)         │
│    • 좁은 통로 통과                │
│                                    │
│ 3. 성능 비교                       │
│    • Potential Field vs DWA        │
│    • 경로 길이                     │
│    • 계산 시간                     │
│    • 안전 여유                     │
│                                    │
│ 4. 실시간 시뮬레이션               │
│    • 50Hz 실행                     │
│    • 센서 노이즈 추가              │
│    • 지연 시간 시뮬레이션           │
└────────────────────────────────────┘

예상 시간: 4~5시간
난이도: ★★★★☆
```

---

## 실습 과제 3: PX4 SITL 통합

```
┌────────────────────────────────────┐
│ 목표: 실제 드론에 통합 테스트       │
├────────────────────────────────────┤
│ 1. PX4 SITL 설정                   │
│    • Gazebo 시뮬레이션 실행         │
│    • LiDAR 플러그인 추가            │
│    • Collision Prevention 활성화   │
│                                    │
│ 2. 파라미터 설정                   │
│    • CP_DIST = 5.0                 │
│    • CP_GUIDE_ANG = 30.0           │
│    • MPC_COL_PREV_D = 1            │
│                                    │
│ 3. 테스트 시나리오                 │
│    • 복도 비행 (폭 3m)             │
│    • 장애물 우회 (큐브 3개)         │
│    • 동적 장애물 (움직이는 물체)    │
│                                    │
│ 4. 로그 분석                       │
│    • obstacle_distance 토픽        │
│    • velocity_setpoint 변화        │
│    • 실제 vs 명령 경로 비교         │
└────────────────────────────────────┘

예상 시간: 3~4시간
난이도: ★★★★☆
```

---

## 실습 환경

### Python Potential Field (슬라이드 52 참조)

```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation

# Potential Field 객체 생성
pf = PotentialField(k_att=1.0, k_rep=100.0, 
                    d_safe=5.0, v_max=5.0)

# 환경 설정
current = np.array([0.0, 0.0, 0.0])
goal = np.array([50.0, 0.0, 0.0])
obstacles = [
    np.array([10.0, 0.0, 0.0]),
    np.array([25.0, 5.0, 0.0]),
    np.array([40.0, -3.0, 0.0])
]

# 시뮬레이션
path = [current.copy()]
for t in np.arange(0, 30, 0.1):
    velocity = pf.compute_velocity(current, goal, 
                                   obstacles)
    current += velocity * 0.1
    path.append(current.copy())
    
    if np.linalg.norm(goal - current) < 1.0:
        break

# 시각화
path = np.array(path)
plt.plot(path[:, 0], path[:, 1], 'b-', linewidth=2)
plt.plot(goal[0], goal[1], 'g*', markersize=20)
for obs in obstacles:
    circle = plt.Circle((obs[0], obs[1]), 2.0, 
                       color='r', alpha=0.3)
    plt.gca().add_patch(circle)
plt.axis('equal')
plt.grid()
plt.show()
```

---

## 추가 학습 자료

```
📚 공식 문서
- PX4 Collision Prevention: 
  https://docs.px4.io/main/en/computer_vision/collision_prevention.html
- ArduPilot Avoidance: 
  https://ardupilot.org/copter/docs/common-oa-bendyruler.html

📹 동영상
- Potential Field Visualization
- DWA Algorithm Explained
- PX4 Collision Prevention Demo

📖 논문
- "The Vector Field Histogram" (Borenstein, 1991)
- "Dynamic Window Approach" (Fox et al., 1997)
- "Real-time Obstacle Avoidance for UAVs" (2015)

💻 코드 저장소
- PX4 collision_prevention: 
  src/modules/collision_prevention/
- ArduPilot AP_Avoidance: 
  libraries/AP_Avoidance/
- Python Robotics: 
  https://github.com/AtsushiSakai/PythonRobotics
  (potential_field, dwa)
```

---

## 다음 주 예고

```
┌────────────────────────────────────┐
│ 6주차: 통합 프로젝트                │
├────────────────────────────────────┤
│ • 5개 알고리즘 통합                │
│   - EKF 센서 융합                  │
│   - PID 제어                       │
│   - 모터 믹싱                      │
│   - 경로 계획                      │
│   - 장애물 회피                    │
│                                    │
│ • 완전 자율 미션                   │
│   - 출발 → 웨이포인트 → 목표       │
│   - 장애물 자동 회피               │
│   - 안전 착륙                      │
│                                    │
│ • 캡스톤 프로젝트                  │
│   - 실제 드론 구현                 │
│   - 발표 및 시연                   │
└────────────────────────────────────┘
```

---

## 발표 스크립트

"장애물 회피를 정리하겠습니다. 3가지 핵심 알고리즘은 Potential Field가 간단하고 직관적이며 실내 단순 환경에 적합하고, DWA는 최적이고 안전하며 복잡한 환경에 적합하며, VFH는 실시간이고 효율적이며 LiDAR 데이터에 적합합니다. 핵심 원리는 조기 감지 4~6m, 점진적 반응, 안전 여유 최소 1m, 센서 융합, 중앙 복귀입니다.

실습 과제 1은 Python으로 Potential Field를 구현합니다. 인력/척력 계산, matplotlib 애니메이션, 파라미터 튜닝, Local Minima 해결을 다룹니다.

실습 과제 2는 DWA를 구현합니다. 동적 윈도우 계산, 10×10 후보 샘플링, 점수 함수, 복잡한 환경 테스트, Potential Field vs DWA 성능 비교, 실시간 50Hz 시뮬레이션을 수행합니다.

실습 과제 3은 PX4 SITL에 통합합니다. Gazebo에 LiDAR 플러그인을 추가하고, CP_DIST=5.0 등 파라미터를 설정하며, 복도 비행과 장애물 우회를 테스트하고, obstacle_distance 토픽과 velocity_setpoint 로그를 분석합니다.

다음 주는 통합 프로젝트입니다. 5개 알고리즘(EKF, PID, 모터 믹싱, 경로 계획, 장애물 회피)을 통합하여 완전 자율 미션을 수행하고, 캡스톤 프로젝트로 실제 드론을 구현하여 발표하고 시연합니다."

---
---

# 🎓 부록: 발표 팁

## 시간 배분 (50분 기준)

```
슬라이드 50-51: 개요 및 센서 (10분)
슬라이드 52-54: 알고리즘 3종 (20분)
슬라이드 55-56: 데이터 처리 & 통합 (12분)
슬라이드 57: 실전 예시 (5분)
슬라이드 58: 요약 및 실습 (3분)
```

## 강조 포인트

```
1. "왜 장애물 회피가 필요한가"
   - 사고의 30% 차지
   - 안전의 최후 방어선
   - 법적 요구사항

2. 알고리즘 선택
   - Potential Field: 간단
   - DWA: 최적
   - VFH: 실시간
   - 용도에 따라 선택

3. 실전 중요성
   - 실내 복도 시나리오
   - 센서 융합
   - PX4/ArduPilot 통합
```

## 데모 제안

```
라이브 데모 (시간 허락 시):
1. Python Potential Field
   - 3개 장애물 회피
   - 파라미터 변경 효과
2. PX4 SITL
   - Gazebo 복도 비행
   - 실시간 회피 동작
3. 센서 데이터 시각화
   - LiDAR 점군
   - 히스토그램
```

---

**훌륭한 강의 되시길 바랍니다! 🚁**
